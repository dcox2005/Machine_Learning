{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14fea75-0851-4f1a-acf4-ea719ecdf949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESSFUL RUN!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import code_logistic_regression.logistic_regression as logic\n",
    "import sys\n",
    "from code_misc.utils import MyUtils\n",
    "\n",
    "\n",
    "def main():\n",
    "    (X_train,y_train,X_test,y_test) = loadData()\n",
    "    passedGD = passedSGD = False\n",
    "    testSigmoid()\n",
    "    passedGD = testGD(X_train,y_train,X_test,y_test)\n",
    "    passedSGD = testSGD(X_train,y_train,X_test,y_test)\n",
    "    if passedGD and passedSGD:\n",
    "        print(\"SUCCESSFUL RUN!\")\n",
    "    else:\n",
    "        print(f'PassedGD: {passedGD}, PassedSGD: {passedSGD}')\n",
    "        print(\"Non-shuffling of the data is assumed as well for the tester's data.\")\n",
    "\n",
    "\n",
    "def testGD(X_train,y_train,X_test,y_test):\n",
    "    errors = loadErrors('GD_Error.npz')\n",
    "    row = 0\n",
    "    passed = True\n",
    "\n",
    "    for lam in [0,10]:\n",
    "        for z_r in [1,2]:\n",
    "            for eta in [0.01,0.001]:\n",
    "                log = logic.LogisticRegression() #Create a new lr object each time. No assumption made that the weights will reset.\n",
    "                log.fit(X_train, y_train, lam = lam, eta = eta, iterations = 10000, SGD = False, mini_batch_size = 20, degree = z_r)\n",
    "                train_error = log.error(X_train, y_train)\n",
    "                test_error = log.error(X_test, y_test)\n",
    "\n",
    "                (mikes_train_error,mikes_test_error) = errors[row]\n",
    "                row+=1\n",
    "                if not inThreshold(train_error,mikes_train_error) or not inThreshold(test_error,mikes_test_error):\n",
    "                    print(f'For GD, and the following params:\\nlam: {lam}, z_r: {z_r}, eta: {eta}')\n",
    "                    print(f'Expected train/test error:\\n{mikes_train_error}, {mikes_test_error}')\n",
    "                    print(f'Found train/test error:\\n{train_error}, {test_error}\\n')\n",
    "                    passed = False\n",
    "    if not passed:\n",
    "        print(\"Please note that for Gradient descent, 0 initialization of the weights is assumed.\")\n",
    "        print(\"Due to randomness resulting from shuffling the data, minor differences can be safely ignored.\")\n",
    "    return passed\n",
    "\n",
    "def testSGD(X_train,y_train,X_test,y_test):\n",
    "    errors = loadErrors('SGD_Error.npz')\n",
    "    row = 0\n",
    "    passed = True\n",
    "\n",
    "    n,d = X_train.shape\n",
    "    for lam in [0,1]:\n",
    "        for z_r in [1,2]:\n",
    "            for eta in [0.01,0.001]:\n",
    "                for mbs in [1,20,n]:\n",
    "                    log = logic.LogisticRegression() #Create a new log object each time. No assumption made that the weights will reset.\n",
    "                    log.fit(X_train, y_train, lam = lam, eta = eta, iterations = 10000, SGD = True, mini_batch_size = mbs, degree = z_r)\n",
    "                    train_error = log.error(X_train, y_train)\n",
    "                    test_error = log.error(X_test, y_test)\n",
    "\n",
    "                    (mikes_train_error,mikes_test_error) = errors[row]\n",
    "                    row+=1\n",
    "                    if not inThreshold(train_error,mikes_train_error) or not inThreshold(test_error,mikes_test_error):\n",
    "                        print(f'For SGD, and the following params:\\nlam: {lam}, z_r: {z_r}, eta: {eta}')\n",
    "                        print(f'Expected train/test error:\\n{mikes_train_error}, {mikes_test_error}')\n",
    "                        print(f'Found train/test error:\\n{train_error}, {test_error}\\n')\n",
    "                        passed = False\n",
    "    if not passed:\n",
    "        print(\"Please note that for Stochastic Gradient descent, 0 initialization of the weights is assumed.\")\n",
    "        print(\"Due to randomness resulting from shuffling the data, minor differences can be safely ignored.\")\n",
    "    return passed\n",
    "\n",
    "\n",
    "def testSigmoid():\n",
    "    actualValue = [0.5,0.7310586,0.8807971,0.2689414]\n",
    "    i = 0\n",
    "    for s in [0,1,2,-1]:\n",
    "        assert inThreshold(logic.LogisticRegression._sigmoid(s),actualValue[i],0.00001), f\"Incorrect sigmoid value, expected {actualValue[i]}, but found {logic.LogisticRegression._sigmoid(s)} for s = {s}\"\n",
    "        i += 1\n",
    "\n",
    "def inThreshold(x1, x2, threshold=1.1):\n",
    "    return abs(x1 - x2) < threshold\n",
    "\n",
    "def loadData(data_set='ionoshpere'):\n",
    "    #Reads the files into pandas dataframes from the respective .csv files.\n",
    "    path = 'code_logistic_regression/ionosphere'\n",
    "    df_X_train = pd.read_csv(f'{path}/X_train.csv', header=None)\n",
    "    df_y_train = pd.read_csv(f'{path}/y_train.csv', header=None)\n",
    "    df_X_test = pd.read_csv(f'{path}/X_test.csv', header=None)\n",
    "    df_y_test = pd.read_csv(f'{path}/y_test.csv', header=None)\n",
    "\n",
    "    #Convert the input data into numpy arrays and normalize.\n",
    "    X_train = df_X_train.to_numpy()\n",
    "    X_test = df_X_test.to_numpy()\n",
    "    n_train = X_train.shape[0]\n",
    "\n",
    "    X_all = MyUtils.normalize_neg1_pos1(np.concatenate((X_train, X_test), axis=0))\n",
    "    X_train = X_all[:n_train]\n",
    "    X_test = X_all[n_train:]\n",
    "\n",
    "    y_train = df_y_train.to_numpy()\n",
    "    y_test = df_y_test.to_numpy()\n",
    "\n",
    "    #Insure that the data correctly loaded in.\n",
    "    assert X_train.shape == (280, 34), \"Incorrect input, expected (280, 34), found \" + X_train.shape\n",
    "    assert y_train.shape == (280, 1), \"Incorrect input, expected (280, 1), found \" + y_train.shape\n",
    "    assert X_test.shape  == (71, 34), \"Incorrect input, expected (71, 34), found \" + X_test.shape\n",
    "    assert y_test.shape  == (71, 1), \"Incorrect input, expected (71, 1), found \" + y_test.shape\n",
    "\n",
    "    return (X_train,y_train,X_test,y_test)\n",
    "\n",
    "def loadErrors(file):\n",
    "    container = np.load(file)\n",
    "    data = [container[key] for key in container]\n",
    "    errors = np.array(data)\n",
    "    return errors\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
